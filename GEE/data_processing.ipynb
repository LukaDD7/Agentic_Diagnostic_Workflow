{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理原始的10个种子下每个hadm_id以及相应的正误label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adw_all = pd.read_excel(\n",
    "    '/media/luzhenyang/project/agent_graph_diag/statistics/statistical_result_of_diagnosis.xlsx',\n",
    "    sheet_name='Accuracy_easy_to_call_tool(bp)'\n",
    ")\n",
    "adw_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 所有种子ID列表\n",
    "seed_list = [1, 4, 7, 9, 10, 20, 23, 42, 71, 96]\n",
    "\n",
    "# 建立一个总表来记录所有hadm_id和其seed\n",
    "all_ids = []\n",
    "\n",
    "for seed in seed_list:\n",
    "    seed_path = f'/media/luzhenyang/project/agent_graph_diag/subset_ids_{seed}.csv'\n",
    "    seed_df = pd.read_csv(seed_path)\n",
    "    seed_df['seed'] = seed\n",
    "    all_ids.append(seed_df)\n",
    "\n",
    "id_all_df = pd.concat(all_ids, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法列表\n",
    "methods = ['own', 'strict', 'lenient', 'FI', 'CoT']\n",
    "\n",
    "# 初始化结果表\n",
    "result_all = []\n",
    "\n",
    "for seed in seed_list:\n",
    "    for method in methods:\n",
    "        file_path = f'/media/luzhenyang/project/agent_graph_diag/results/agent_graph_subset_{seed}_{method}.csv'\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 处理\"对\"和\"错\"：建议你确认下列的字段名\n",
    "        if 'result' in df.columns:\n",
    "            df['correct'] = df['result'].apply(lambda x: 1 if x == '对' else 0)\n",
    "        elif '诊断正确' in df.columns:\n",
    "            df['correct'] = df['诊断正确'].apply(lambda x: 1 if x == '对' else 0)\n",
    "        else:\n",
    "            raise ValueError(f\"请检查{file_path}的列名，找不到结果字段\")\n",
    "\n",
    "        df['seed'] = seed\n",
    "        df['method'] = method\n",
    "        result_all.append(df[['hadm_id', 'seed', 'method', 'correct']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载主表（诊断结果，只有Index，无hadm_id）\n",
    "adw_all = pd.read_excel(\n",
    "    '/media/luzhenyang/project/agent_graph_diag/statistics/statistical_result_of_diagnosis.xlsx',\n",
    "    sheet_name='Accuracy_easy_to_call_tool(bp)'\n",
    ")\n",
    "\n",
    "# 所有种子编号和方法\n",
    "seeds = [1, 4, 7, 9, 10, 20, 23, 42, 71, 96]\n",
    "methods = ['own', 'strict', 'lenient', 'FI', 'CoT']\n",
    "\n",
    "# 存储所有数据\n",
    "records = []\n",
    "\n",
    "# 遍历种子和方法\n",
    "for seed in seeds:\n",
    "    # 加载 hadm_id\n",
    "    seed_id_path = f'/media/luzhenyang/project/agent_graph_diag/subset_ids_{seed}.csv'\n",
    "    seed_df = pd.read_csv(seed_id_path)\n",
    "    hadm_ids = seed_df['hadm_id'].tolist()\n",
    "\n",
    "    for method in methods:\n",
    "        col_name = f\"{seed}_{method}\"\n",
    "        if col_name not in adw_all.columns:\n",
    "            print(f\"⚠️ 缺失列：{col_name}\")\n",
    "            continue\n",
    "        \n",
    "        # 获取当前列的结果（对/错/空）并转换为 0/1\n",
    "        results = adw_all[col_name].fillna(\"\").astype(str).str.strip()\n",
    "        results_binary = results.apply(lambda x: 1 if x == '对' else 0)\n",
    "        \n",
    "        # 创建记录\n",
    "        for i in range(len(hadm_ids)):\n",
    "            records.append({\n",
    "                'hadm_id': hadm_ids[i],\n",
    "                'seed': seed,\n",
    "                'method': method,\n",
    "                'result': results_binary.iloc[i]\n",
    "            })\n",
    "\n",
    "# 构建长格式数据表\n",
    "df_long = pd.DataFrame(records)\n",
    "\n",
    "# 检查\n",
    "print(df_long.head())\n",
    "print(df_long['result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_longformer_pre = pd.read_csv('/media/luzhenyang/project/agent_graph_diag/lm_classification/training_logs_longformer_random_seeds/predictions_seed_1.csv')\n",
    "print(cli_longformer_pre.columns)\n",
    "print(cli_longformer_pre.shape)\n",
    "print(cli_longformer_pre.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 原主实验数据\n",
    "# df_all = pd.read_csv(...)  # 请确保你事先加载了主表\n",
    "\n",
    "# 临时列表收集所有 longformer 数据\n",
    "longformer_list = []\n",
    "\n",
    "# 所有种子\n",
    "seeds = [1, 4, 7, 9, 10, 20, 23, 42, 71, 96]\n",
    "\n",
    "# 预测文件夹路径\n",
    "# base_path = '/media/luzhenyang/project/agent_graph_diag/lm_classification/training_logs_normal_longformer_rs'\n",
    "base_path = '/media/luzhenyang/project/agent_graph_diag/lm_classification/training_logs_longformer_random_seeds'\n",
    "\n",
    "for seed in tqdm(seeds):\n",
    "    file_path = os.path.join(base_path, f'predictions_seed_{seed}.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❗ 文件不存在: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 处理 hadm_id：从 tensor(12345678) 提取数字\n",
    "    df['hadm_id'] = df['hadm_id'].astype(str).str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "    # 添加缺失列\n",
    "    df['seed'] = seed\n",
    "    df['method'] = 'clinical_longformer'\n",
    "    df['result'] = (df['label'] == df['pred']).astype(int)\n",
    "\n",
    "    # 保留所需列\n",
    "    df = df[['hadm_id', 'seed', 'method', 'result']]\n",
    "\n",
    "    # 去重：避免同一个 seed 下同一个 hadm_id 多次出现\n",
    "    df = df.drop_duplicates(subset=['hadm_id', 'seed'])\n",
    "\n",
    "    longformer_list.append(df)\n",
    "\n",
    "# 合并所有 longformer 数据\n",
    "df_longformer_all = pd.concat(longformer_list, ignore_index=True)\n",
    "\n",
    "# 合并进主 df_all\n",
    "df_all = pd.concat([df_long, df_longformer_all], ignore_index=True)\n",
    "\n",
    "# 可选检查\n",
    "print(df_longformer_all.shape)\n",
    "print(df_longformer_all.duplicated(subset=['hadm_id', 'seed']).sum())\n",
    "\n",
    "df_all  # 展示主表最终内容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 原主实验数据\n",
    "# df_all = pd.read_csv(...)  # 请确保你事先加载了主表\n",
    "\n",
    "# 临时列表收集所有 longformer 数据\n",
    "longformer_list = []\n",
    "\n",
    "# 所有种子\n",
    "seeds = [1, 4, 7, 9, 10, 20, 23, 42, 71, 96]\n",
    "\n",
    "# 预测文件夹路径\n",
    "base_path = '/media/luzhenyang/project/agent_graph_diag/lm_classification/training_logs_normal_longformer_rs'\n",
    "# base_path = '/media/luzhenyang/project/agent_graph_diag/lm_classification/training_logs_longformer_random_seeds'\n",
    "\n",
    "for seed in tqdm(seeds):\n",
    "    file_path = os.path.join(base_path, f'predictions_seed_{seed}.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❗ 文件不存在: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 处理 hadm_id：从 tensor(12345678) 提取数字\n",
    "    df['hadm_id'] = df['hadm_id'].astype(str).str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "    # 添加缺失列\n",
    "    df['seed'] = seed\n",
    "    df['method'] = 'longformer'\n",
    "    df['result'] = (df['label'] == df['pred']).astype(int)\n",
    "\n",
    "    # 保留所需列\n",
    "    df = df[['hadm_id', 'seed', 'method', 'result']]\n",
    "\n",
    "    # 去重：避免同一个 seed 下同一个 hadm_id 多次出现\n",
    "    df = df.drop_duplicates(subset=['hadm_id', 'seed'])\n",
    "\n",
    "    longformer_list.append(df)\n",
    "\n",
    "# 合并所有 longformer 数据\n",
    "df_longformer_all = pd.concat(longformer_list, ignore_index=True)\n",
    "\n",
    "# 合并进主 df_all\n",
    "df_all = pd.concat([df_all, df_longformer_all], ignore_index=True)\n",
    "\n",
    "# 可选检查\n",
    "print(df_longformer_all.shape)\n",
    "print(df_longformer_all.duplicated(subset=['hadm_id', 'seed']).sum())\n",
    "\n",
    "df_all  # 展示主表最终内容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['method'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('/media/luzhenyang/project/agent_graph_diag/GLMM/df_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # Keep numpy for potential future use\n",
    "\n",
    "# --- STEP 1: LOAD YOUR REAL DATA (替换掉整个模拟部分) ---\n",
    "# 假设你所有的真实实验结果都保存在这个文件里\n",
    "real_results_path = \"/media/luzhenyang/project/agent_graph_diag/GLMM/df_all.csv\" \n",
    "df_all = pd.read_csv(real_results_path)\n",
    "\n",
    "# --- 检查数据，确保一切正确 ---\n",
    "# 你可以取消下面这行的注释来验证\n",
    "# unique_patients = df_all['hadm_id'].nunique()\n",
    "# print(f\"Successfully loaded data. Found {unique_patients} unique patients.\")\n",
    "# 如果这里打印出 659，那就对了！\n",
    "\n",
    "# --- 从这里开始，后面的代码基本不变 ---\n",
    "\n",
    "# 设定方法的比较基准 (reference group)\n",
    "all_methods = ['own', 'lenient', 'strict', 'FI', 'CoT', 'clinical_longformer', 'longformer']\n",
    "# all_methods = ['ADW-own', 'ADW-lenient', 'ADW-strict', 'Vanilla Prompting', 'CoT', 'Clinical Longformer', 'Longformer']\n",
    "df_all['method'] = pd.Categorical(df_all['method'], categories=all_methods, ordered=True)\n",
    "\n",
    "# 拟合 GEE 模型\n",
    "print(\"--- Fitting GEE model on REAL experimental data ---\")\n",
    "model_gee = smf.gee(\n",
    "    \"result ~ method\", \n",
    "    data=df_all, \n",
    "    groups=df_all[\"hadm_id\"], # GEE会在这里找到659个groups\n",
    "    family=sm.families.Binomial(),\n",
    "    cov_struct=sm.cov_struct.Exchangeable()\n",
    ")\n",
    "result_gee = model_gee.fit()\n",
    "\n",
    "print(\"--- GEE model fitting successful! ---\")\n",
    "# 这一次，这里的输出应该会显示 \"No. clusters: 659\"\n",
    "print(result_gee.summary())\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# ✅ 3. 提取并整理结果\n",
    "# ----------------------\n",
    "params = result_gee.params\n",
    "conf_int = result_gee.conf_int()\n",
    "p_values = result_gee.pvalues\n",
    "\n",
    "# 计算 Odds Ratios\n",
    "odds_ratios = np.exp(params)\n",
    "or_low_ci = np.exp(conf_int[0])\n",
    "or_high_ci = np.exp(conf_int[1])\n",
    "\n",
    "# 创建一个清晰的结果表格\n",
    "results_table = pd.DataFrame({\n",
    "    'Method': params.index,\n",
    "    'Log(OR)': params.values,\n",
    "    'P-value': p_values.values,\n",
    "    'Odds Ratio (OR)': odds_ratios.values,\n",
    "    '95% CI Low': or_low_ci.values,\n",
    "    '95% CI High': or_high_ci.values\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# 把基准（Intercept）的名字改成更清晰的 'own (Reference)'\n",
    "results_table.loc[results_table['Method'] == 'Intercept', 'Method'] = f\"{all_methods[0]} (Reference)\"\n",
    "results_table.loc[results_table['Method'] == f\"{all_methods[0]} (Reference)\", 'Odds Ratio (OR)'] = 1.0\n",
    "results_table.loc[results_table['Method'] == f\"{all_methods[0]} (Reference)\", ['95% CI Low', '95% CI High']] = 1.0\n",
    "\n",
    "\n",
    "# 清理其他方法的名称\n",
    "results_table['Method'] = results_table['Method'].str.replace('method[T.', '', regex=False).str.replace(']', '', regex=False)\n",
    "\n",
    "# ✅ 3.1. 保存统计结果到 CSV 文件\n",
    "# ----------------------\n",
    "results_filename = \"/media/luzhenyang/project/agent_graph_diag/GLMM/diagnostic_methods_gee_results.csv\"\n",
    "# results_table.to_csv(results_filename, index=False)\n",
    "print(f\"\\n--- Statistical results saved to {results_filename} ---\")\n",
    "\n",
    "print(\"\\n--- Final Odds Ratios Table for Manuscript ---\")\n",
    "print(results_table)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# ✅ 4. 可视化结果 (森林图 Forest Plot)\n",
    "# ----------------------\n",
    "# 准备绘图用的数据框，确保顺序正确\n",
    "plot_df = results_table.copy()\n",
    "plot_df['Method'] = plot_df['Method'].replace({'FI': 'Vanilla Prompting'})\n",
    "plot_df['Method'] = plot_df['Method'].replace({'own (Reference)': 'ADW-own'})\n",
    "plot_df['Method'] = plot_df['Method'].replace({'lenient': 'ADW-lenient'})\n",
    "plot_df['Method'] = plot_df['Method'].replace({'strict': 'ADW-strict'})\n",
    "plot_df['Method'] = plot_df['Method'].replace({'CoT': 'Chain-of-Thought'})\n",
    "plot_df['Method'] = plot_df['Method'].replace({'clinical_longformer': 'Clinical Longformer'})\n",
    "plot_df['Method'] = plot_df['Method'].replace({'longformer': 'Longformer'})\n",
    "\n",
    "\n",
    "plot_df['Method'] = pd.Categorical(plot_df['Method'], categories=plot_df['Method'].tolist(), ordered=True)\n",
    "plot_df = plot_df.sort_values(by='Method', ascending=False) # 倒序，这样在图上是正序\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 绘制点和误差线\n",
    "ax.errorbar(\n",
    "    x=plot_df['Odds Ratio (OR)'],\n",
    "    y=plot_df['Method'],\n",
    "    xerr=[plot_df['Odds Ratio (OR)'] - plot_df['95% CI Low'], plot_df['95% CI High'] - plot_df['Odds Ratio (OR)']],\n",
    "    fmt='o', # 'o' for point marker\n",
    "    color='black',\n",
    "    ecolor='black',\n",
    "    capsize=5,\n",
    "    elinewidth=1.5,\n",
    "    markersize=7,\n",
    "    markerfacecolor='royalblue',\n",
    "    markeredgecolor='black'\n",
    ")\n",
    "\n",
    "# 绘制无效线\n",
    "ax.axvline(x=1.0, linestyle='--', color='red', linewidth=1.2)\n",
    "\n",
    "# 设置对数刻度\n",
    "ax.set_xscale('log')\n",
    "\n",
    "# 美化图表\n",
    "# ax.set_title('Comparison of Diagnostic Methods vs. Reference (ADW-own)', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Odds Ratio (OR) and 95% Confidence Interval (Log Scale)', fontsize=12)\n",
    "ax.set_ylabel('Method', fontsize=12)\n",
    "# 根据你的方法数量调整x轴范围和刻度\n",
    "ax.set_xticks([0.1, 0.5, 1.0, 2.0, 5.0])\n",
    "ax.get_xaxis().set_major_formatter(plt.ScalarFormatter())\n",
    "\n",
    "# 在图的右侧添加OR和CI的文字标注，更专业\n",
    "for i, row in plot_df.iterrows():\n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 1.1, # 将文本放在图右侧\n",
    "        row['Method'],\n",
    "        f\"{row['Odds Ratio (OR)']:.2f} ({row['95% CI Low']:.2f} - {row['95% CI High']:.2f})\",\n",
    "        va='center',\n",
    "        ha='left'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "# ✅ 4.1. 保存高质量图片\n",
    "# ----------------------\n",
    "# dpi=300 是大多数期刊要求的最低分辨率\n",
    "figure_filename = \"/media/luzhenyang/project/agent_graph_diag/GLMM/diagnostic_methods_forest_plot_v2.png\" # TIFF 或 PDF 格式更适合出版\n",
    "plt.savefig(figure_filename, dpi=300, bbox_inches='tight') # bbox_inches='tight' 避免标签被截断\n",
    "print(f\"--- Forest plot saved to {figure_filename} ---\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gee_stats = pd.read_csv('/media/luzhenyang/project/agent_graph_diag/GLMM/diagnostic_methods_gee_results.csv')\n",
    "print(gee_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.stats.power as smp\n",
    "import pandas as pd\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def cohen_h(p1, p2):\n",
    "    \"\"\"Calculates Cohen's h for effect size between two proportions.\"\"\"\n",
    "    return 2 * (np.arcsin(np.sqrt(p1)) - np.arcsin(np.sqrt(p2)))\n",
    "\n",
    "def log_odds_to_prob(log_odds):\n",
    "    \"\"\"Converts log odds to probability.\"\"\"\n",
    "    return np.exp(log_odds) / (1 + np.exp(log_odds))\n",
    "\n",
    "# --- Parameters from your FINAL GEE results ---\n",
    "alpha = 0.05\n",
    "\n",
    "# Log_odds for the reference group ('own') is the Intercept from the GEE output\n",
    "log_odds_own = 2.5483\n",
    "p_own = log_odds_to_prob(log_odds_own)\n",
    "\n",
    "# Calculate log_odds for all comparison groups\n",
    "all_methods_log_odds = {\n",
    "    'strict': log_odds_own - 1.5027,\n",
    "    'lenient': log_odds_own - 0.1886,\n",
    "    'FI': log_odds_own - 0.7335,\n",
    "    'CoT': log_odds_own - 0.2654,\n",
    "    'clinical_longformer': log_odds_own - 3.2909,\n",
    "    'longformer': log_odds_own - 3.3024\n",
    "}\n",
    "\n",
    "# Convert log_odds to probabilities to display in the table\n",
    "all_methods_prob = {name: log_odds_to_prob(lo) for name, lo in all_methods_log_odds.items()}\n",
    "\n",
    "# --- Key Sample Sizes ---\n",
    "n_gee_correct = 659  # The correct number of unique patients (clusters)\n",
    "n_naive_flawed = 10  # The flawed number of sample runs for comparison\n",
    "\n",
    "# --- Analysis 1: Power of the Correct GEE Model ---\n",
    "print(f\"Calculating power for GEE model with n = {n_gee_correct} unique patients...\")\n",
    "power_gee_final = {}\n",
    "for name, p_method in all_methods_prob.items():\n",
    "    effect_size_h = cohen_h(p_own, p_method)\n",
    "    power = smp.NormalIndPower().power(\n",
    "        effect_size=abs(effect_size_h), \n",
    "        nobs1=n_gee_correct, \n",
    "        alpha=alpha,\n",
    "        ratio=1.0, \n",
    "        alternative='two-sided'\n",
    "    )\n",
    "    power_gee_final[name] = power\n",
    "\n",
    "# --- Analysis 2: Power of the Naive Test ---\n",
    "print(f\"Calculating power for naive test with n = {n_naive_flawed} sample runs...\")\n",
    "power_naive_final = {}\n",
    "for name, p_method in all_methods_prob.items():\n",
    "    effect_size_h = cohen_h(p_own, p_method)\n",
    "    power = smp.TTestIndPower().power(\n",
    "        effect_size=abs(effect_size_h),\n",
    "        nobs1=n_naive_flawed,\n",
    "        alpha=alpha,\n",
    "        ratio=1.0, \n",
    "        alternative='two-sided'\n",
    "    )\n",
    "    power_naive_final[name] = power\n",
    "\n",
    "# --- Create the Final Comparison Table ---\n",
    "df_power_final = pd.DataFrame({\n",
    "    'Comparison': [f\"'own' vs. '{name}'\" for name in all_methods_prob.keys()],\n",
    "    'Observed Accuracy (own)': [f\"{p_own:.1%}\" for _ in all_methods_prob],\n",
    "    'Observed Accuracy (Comparison)': [f\"{p:.1%}\" for p in all_methods_prob.values()],\n",
    "    f'Power of GEE Model (n={n_gee_correct})': [f\"{power_gee_final[name]:.1%}\" for name in all_methods_prob.keys()],\n",
    "    f'Power of Naive Test (n={n_naive_flawed})': [f\"{power_naive_final[name]:.1%}\" for name in all_methods_prob.keys()]\n",
    "})\n",
    "\n",
    "# --- Sort table by GEE power for clear presentation ---\n",
    "gee_power_numeric = [power_gee_final[name] for name in all_methods_prob.keys()]\n",
    "df_power_final['gee_power_numeric'] = gee_power_numeric\n",
    "df_power_final = df_power_final.sort_values(by='gee_power_numeric', ascending=False).drop(columns=['gee_power_numeric'])\n",
    "\n",
    "# --- Display the final results ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"  Final Post-hoc Statistical Power Analysis Table  \")\n",
    "print(\"=\"*50)\n",
    "print(df_power_final.to_markdown(index=False, tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag_diag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
